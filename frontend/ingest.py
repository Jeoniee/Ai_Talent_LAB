# ingest.py
# ëª©ì :
#   data/ í´ë” ì•ˆì˜ PDF/TXT ë¬¸ì„œë¥¼ ì½ì–´ í…ìŠ¤íŠ¸ ì²­í¬ë¡œ ë‚˜ëˆˆ ë’¤
#   Azure OpenAI ì„ë² ë”©ìœ¼ë¡œ ë²¡í„°í™”í•˜ì—¬ ChromaDBì— ì €ì¥.
#   (--faiss ì˜µì…˜ì„ ì“°ë©´ FAISS ë°±ì—… ì¸ë±ìŠ¤ë„ ìƒì„±)

import argparse     # ì»¤ë§¨ë“œë¼ì¸ ì˜µì…˜ íŒŒì‹±
import os
import shutil
from typing import List, Tuple

# LangChain + OpenAI ê´€ë ¨ ëª¨ë“ˆ
from langchain_openai import AzureOpenAIEmbeddings
from langchain_community.vectorstores import Chroma, FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter

# utils.pyì—ì„œ ê³µí†µ ì„¤ì •/í•¨ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
from utils import load_and_ingest, VDB_DIR, AOAI_ENDPOINT, AOAI_API_KEY, DEPLOY_EMBED

# -----------------------------
# ì „ì—­ ì„¤ì •ê°’
# -----------------------------
CHUNK_SIZE = 1000          # ì²­í¬ í¬ê¸° (ë¬¸ì„œ ì˜ë¼ë‚´ëŠ” ë‹¨ìœ„)
CHUNK_OVERLAP = 150        # ì²­í¬ ê°„ ì˜¤ë²„ë© (ì•ë’¤ ê²¹ì¹˜ê²Œ í•´ì„œ ë§¥ë½ ìœ ì§€)

# -----------------------------
# í™˜ê²½ë³€ìˆ˜ ì²´í¬ & ì„ë² ë”© ì¤€ë¹„
# -----------------------------
def _require_env():
    """í™˜ê²½ë³€ìˆ˜(AOAI_ENDPOINT/API_KEY) ì„¤ì • ì—¬ë¶€ í™•ì¸"""
    if not AOAI_ENDPOINT or not AOAI_API_KEY:
        raise RuntimeError("AOAI_ENDPOINT ë˜ëŠ” AOAI_API_KEYê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

def get_splitter() -> RecursiveCharacterTextSplitter:
    """í…ìŠ¤íŠ¸ ë¶„í• ê¸° ìƒì„± (RecursiveCharacterTextSplitter)"""
    return RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP, length_function=len,)

def get_embeddings() -> AzureOpenAIEmbeddings:
    """Azure OpenAI ì„ë² ë”© ê°ì²´ ìƒì„±"""
    _require_env()
    return AzureOpenAIEmbeddings(
        azure_deployment=DEPLOY_EMBED,  # .envì—ì„œ ì„¤ì •ëœ ì„ë² ë”© ëª¨ë¸ëª…
        api_key=AOAI_API_KEY,
        azure_endpoint=AOAI_ENDPOINT,
        api_version="2024-06-01",
    )

# -----------------------------
# ë¬¸ì„œ â†’ ì²­í¬ â†’ texts/metadatas
# -----------------------------
def build_payload() -> Tuple[List[str], List[dict]]:
    """
    data/ í´ë”ì—ì„œ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì™€ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ê³ 
    í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸(texts)ì™€ ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸(metadatas)ë¥¼ ë°˜í™˜.
    """
    docs = load_and_ingest()  # utils.load_documents: [{"path":..., "content":...}]
    if not docs:
        raise SystemExit("data/ í´ë”ì— TXT/PDF ë¬¸ì„œë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")

    splitter = get_splitter()
    texts, metas = [], []

    for d in docs:
        chunks = splitter.split_text(d.page_content)
        for ch in chunks:
            if not ch.strip():
                continue
            texts.append(ch)
            metas.append({"source": d.metadata.get("source", "unknown")})

    if not texts:
        raise SystemExit("ë¬¸ì„œëŠ” ìˆì—ˆì§€ë§Œ ìœ íš¨í•œ ì²­í¬ë¥¼ ë§Œë“¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    return texts, metas


# -----------------------------
# Chroma / FAISS ë¹Œë”
# -----------------------------
def build_chroma(texts: List[str], metas: List[dict], persist_dir: str):
    """ChromaDB ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥"""
    os.makedirs(persist_dir, exist_ok=True)
    vectordb = Chroma.from_texts(
        texts=texts,
        embedding=get_embeddings(),
        metadatas=metas,
        persist_directory=persist_dir,
    )
    vectordb.persist()


def build_faiss(texts: List[str], metas: List[dict], faiss_dir: str):
    """FAISS ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥ (ë°±ì—…ìš©)"""
    os.makedirs(faiss_dir, exist_ok=True)
    index = FAISS.from_texts(
        texts=texts,
        embedding=get_embeddings(),
        metadatas=metas,
    )
    index.save_local(os.path.join(faiss_dir, "faiss_index"))


# -----------------------------
# ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ (main)
# -----------------------------
def main():
    parser = argparse.ArgumentParser(description="RAG ì¸ë±ìŠ¤ ìƒì„± ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument("--rebuild", action="store_true", help="ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ í›„ ì¬ìƒì„±")
    parser.add_argument("--faiss", action="store_true", help="FAISS ë°±ì—… ì¸ë±ìŠ¤ë„ ìƒì„±")
    args = parser.parse_args()

    chroma_dir = VDB_DIR  # vectordb/ (utils.pyì—ì„œ ë¶ˆëŸ¬ì˜´)
    faiss_dir = os.path.join(VDB_DIR, "faiss_backup")

    # --rebuild ì˜µì…˜: ê¸°ì¡´ ì¸ë±ìŠ¤ í´ë” ì‚­ì œ
    if args.rebuild:
        if os.path.isdir(chroma_dir):
            shutil.rmtree(chroma_dir)
        if os.path.isdir(faiss_dir):
            shutil.rmtree(faiss_dir)
        print(" ê¸°ì¡´ ì¸ë±ìŠ¤ ë””ë ‰í† ë¦¬ ì‚­ì œ ì™„ë£Œ.")

    # ë¬¸ì„œ ë¡œë”© â†’ ì²­í¬ ìƒì„±
    print(" ë¬¸ì„œ ë¡œë”© ë° ì²­í¬ ë¶„í•  ì¤‘â€¦")
    texts, metas = build_payload()
    print(f" ì²­í¬ {len(texts)}ê°œ ì¤€ë¹„ ì™„ë£Œ.ğŸ’–")

    # Chroma ì¸ë±ì‹±
    print(" Chroma ì¸ë±ì‹± ì¤‘â€¦ğŸ’–")
    build_chroma(texts, metas, chroma_dir)
    print(f" Chroma ì¸ë±ìŠ¤ ì™„ë£Œ â†’ {chroma_dir}ğŸ’–")

    # --faiss ì˜µì…˜: FAISS ë°±ì—…ë„ í•¨ê»˜
    if args.faiss:
        print(" FAISS ë°±ì—… ì¸ë±ìŠ¤ ìƒì„± ì¤‘â€¦ğŸ’–")
        build_faiss(texts, metas, faiss_dir)
        print(f" FAISS ì¸ë±ìŠ¤ ì €ì¥ â†’ {faiss_dir}ğŸ’–")



if __name__ == "__main__":
    main()